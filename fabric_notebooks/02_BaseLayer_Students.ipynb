{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e060f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import DeltaTable\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad4bd1",
   "metadata": {},
   "source": [
    "## 1. Transform Student Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2780e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw student details\n",
    "raw_students = spark.table(\"raw_g4s_student_details\")\n",
    "\n",
    "# Transform to base schema matching original C# logic\n",
    "base_students = raw_students.select(\n",
    "    # Composite key matching C# implementation\n",
    "    concat(col(\"_academy_code\"), col(\"_academic_year\"), lit(\"-\"), col(\"id\")).alias(\"StudentId\"),\n",
    "    col(\"_academic_year\").alias(\"DataSet\"),\n",
    "    col(\"_academy_code\").alias(\"Academy\"),\n",
    "    col(\"id\").alias(\"G4SStuId\"),\n",
    "    \n",
    "    # Student name fields\n",
    "    col(\"legal_first_name\").alias(\"LegalFirstName\"),\n",
    "    col(\"legal_last_name\").alias(\"LegalLastName\"),\n",
    "    col(\"preferred_first_name\").alias(\"PreferredFirstName\"),\n",
    "    col(\"preferred_last_name\").alias(\"PreferredLastName\"),\n",
    "    col(\"middle_names\").alias(\"MiddleNames\"),\n",
    "    \n",
    "    # Demographics\n",
    "    col(\"sex\").alias(\"Sex\"),\n",
    "    to_timestamp(col(\"date_of_birth\"), \"yyyy-MM-dd'T'HH:mm:ss'Z'\").alias(\"DateOfBirth\"),\n",
    "    \n",
    "    # Audit columns\n",
    "    col(\"_ingested_at\").alias(\"IngestedAt\"),\n",
    "    current_timestamp().alias(\"TransformedAt\")\n",
    ")\n",
    "\n",
    "# Write to base layer\n",
    "base_students.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .partitionBy(\"Academy\", \"DataSet\") \\\n",
    "    .saveAsTable(\"base_students\")\n",
    "\n",
    "print(f\"✓ Transformed {base_students.count()} student records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db53bb",
   "metadata": {},
   "source": [
    "## 2. Transform Education Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b9d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw education details\n",
    "raw_education = spark.table(\"raw_g4s_education_details\")\n",
    "\n",
    "# Transform to base schema\n",
    "base_education = raw_education.select(\n",
    "    # Foreign key to Students\n",
    "    concat(col(\"_academy_code\"), col(\"_academic_year\"), lit(\"-\"), col(\"student_id\")).alias(\"StudentId\"),\n",
    "    col(\"_academic_year\").alias(\"DataSet\"),\n",
    "    col(\"_academy_code\").alias(\"Academy\"),\n",
    "    \n",
    "    # Education fields (adjust based on actual API response structure)\n",
    "    col(\"admission_date\").alias(\"AdmissionDate\"),\n",
    "    col(\"admission_number\").alias(\"AdmissionNumber\"),\n",
    "    col(\"year_group\").alias(\"YearGroup\"),\n",
    "    col(\"registration_group\").alias(\"RegistrationGroup\"),\n",
    "    col(\"house\").alias(\"House\"),\n",
    "    col(\"upn\").alias(\"UPN\"),\n",
    "    col(\"former_upn\").alias(\"FormerUPN\"),\n",
    "    col(\"enrolment_status\").alias(\"EnrolmentStatus\"),\n",
    "    col(\"leaving_date\").alias(\"LeavingDate\"),\n",
    "    \n",
    "    # Audit columns\n",
    "    col(\"_ingested_at\").alias(\"IngestedAt\"),\n",
    "    current_timestamp().alias(\"TransformedAt\")\n",
    ")\n",
    "\n",
    "# Write to base layer\n",
    "base_education.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .partitionBy(\"Academy\", \"DataSet\") \\\n",
    "    .saveAsTable(\"base_education_details\")\n",
    "\n",
    "print(f\"✓ Transformed {base_education.count()} education detail records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b3ca4",
   "metadata": {},
   "source": [
    "## 3. Transform Student Attributes (General, Demographic, SEND, Sensitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform attribute data\n",
    "def transform_attributes(raw_table_name, attribute_type):\n",
    "    \"\"\"\n",
    "    Transform student attribute data from raw to base layer\n",
    "    Handles nested attribute structure from API\n",
    "    \"\"\"\n",
    "    raw_df = spark.table(raw_table_name)\n",
    "    \n",
    "    # Explode nested attributes if they exist\n",
    "    # The API typically returns attributes as an array of objects\n",
    "    if \"attributes\" in raw_df.columns:\n",
    "        exploded = raw_df.select(\n",
    "            col(\"_academy_code\"),\n",
    "            col(\"_academic_year\"),\n",
    "            col(\"student_id\"),\n",
    "            explode(col(\"attributes\")).alias(\"attribute\")\n",
    "        )\n",
    "        \n",
    "        transformed = exploded.select(\n",
    "            concat(col(\"_academy_code\"), col(\"_academic_year\"), lit(\"-\"), col(\"student_id\")).alias(\"StudentId\"),\n",
    "            col(\"_academic_year\").alias(\"DataSet\"),\n",
    "            col(\"_academy_code\").alias(\"Academy\"),\n",
    "            lit(attribute_type).alias(\"AttributeType\"),\n",
    "            col(\"attribute.name\").alias(\"AttributeName\"),\n",
    "            col(\"attribute.value\").alias(\"AttributeValue\"),\n",
    "            col(\"attribute.id\").alias(\"G4SAttributeId\"),\n",
    "            current_timestamp().alias(\"TransformedAt\")\n",
    "        )\n",
    "    else:\n",
    "        # Handle flat structure if attributes are not nested\n",
    "        transformed = raw_df.select(\n",
    "            concat(col(\"_academy_code\"), col(\"_academic_year\"), lit(\"-\"), col(\"student_id\")).alias(\"StudentId\"),\n",
    "            col(\"_academic_year\").alias(\"DataSet\"),\n",
    "            col(\"_academy_code\").alias(\"Academy\"),\n",
    "            lit(attribute_type).alias(\"AttributeType\"),\n",
    "            current_timestamp().alias(\"TransformedAt\")\n",
    "        )\n",
    "    \n",
    "    return transformed\n",
    "\n",
    "# Transform each attribute type\n",
    "attribute_types = [\n",
    "    (\"raw_g4s_general_attributes\", \"General\"),\n",
    "    (\"raw_g4s_demographic_attributes\", \"Demographic\"),\n",
    "    (\"raw_g4s_send_attributes\", \"SEND\"),\n",
    "    (\"raw_g4s_sensitive_attributes\", \"Sensitive\")\n",
    "]\n",
    "\n",
    "all_attributes = []\n",
    "for raw_table, attr_type in attribute_types:\n",
    "    try:\n",
    "        if spark.catalog.tableExists(raw_table):\n",
    "            df = transform_attributes(raw_table, attr_type)\n",
    "            all_attributes.append(df)\n",
    "            print(f\"✓ Transformed {attr_type} attributes from {raw_table}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error transforming {raw_table}: {str(e)}\")\n",
    "\n",
    "# Union all attribute types\n",
    "if all_attributes:\n",
    "    from functools import reduce\n",
    "    from pyspark.sql import DataFrame\n",
    "    \n",
    "    base_attributes = reduce(DataFrame.union, all_attributes)\n",
    "    \n",
    "    # Write to base layer\n",
    "    base_attributes.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .partitionBy(\"Academy\", \"DataSet\", \"AttributeType\") \\\n",
    "        .saveAsTable(\"base_student_attributes\")\n",
    "    \n",
    "    print(f\"✓ Transformed {base_attributes.count()} total attribute records\")\n",
    "else:\n",
    "    print(\"⚠ No attribute data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a01ac",
   "metadata": {},
   "source": [
    "## 4. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a56b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data quality checks\n",
    "print(\"\\n=== Data Quality Checks ===\")\n",
    "\n",
    "# Check 1: Student counts match between raw and base\n",
    "raw_count = spark.table(\"raw_g4s_student_details\").count()\n",
    "base_count = spark.table(\"base_students\").count()\n",
    "print(f\"Raw student records: {raw_count}\")\n",
    "print(f\"Base student records: {base_count}\")\n",
    "print(f\"Match: {'✓' if raw_count == base_count else '✗'}\")\n",
    "\n",
    "# Check 2: No null StudentIds\n",
    "null_ids = spark.table(\"base_students\").filter(col(\"StudentId\").isNull()).count()\n",
    "print(f\"\\nNull StudentIds: {null_ids} {'✓' if null_ids == 0 else '✗'}\")\n",
    "\n",
    "# Check 3: DateOfBirth validity\n",
    "invalid_dob = spark.table(\"base_students\") \\\n",
    "    .filter((col(\"DateOfBirth\") < lit(\"1900-01-01\")) | (col(\"DateOfBirth\") > current_date())) \\\n",
    "    .count()\n",
    "print(f\"Invalid DateOfBirth records: {invalid_dob} {'✓' if invalid_dob == 0 else '✗'}\")\n",
    "\n",
    "# Check 4: Education details exist for all students\n",
    "students_with_education = spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT s.StudentId) as count\n",
    "    FROM base_students s\n",
    "    INNER JOIN base_education_details e ON s.StudentId = e.StudentId\n",
    "\"\"\").collect()[0][0]\n",
    "print(f\"\\nStudents with education details: {students_with_education}/{base_count}\")\n",
    "\n",
    "print(\"\\n=== Transformation Complete ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b5f3f",
   "metadata": {},
   "source": [
    "## 5. Create Summary Views (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ae94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a denormalized view combining students and education details\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE VIEW vw_students_complete AS\n",
    "SELECT \n",
    "    s.*,\n",
    "    e.AdmissionDate,\n",
    "    e.AdmissionNumber,\n",
    "    e.YearGroup,\n",
    "    e.RegistrationGroup,\n",
    "    e.House,\n",
    "    e.UPN,\n",
    "    e.EnrolmentStatus,\n",
    "    e.LeavingDate\n",
    "FROM base_students s\n",
    "LEFT JOIN base_education_details e ON s.StudentId = e.StudentId\n",
    "\"\"\")\n",
    "\n",
    "print(\"✓ Created vw_students_complete view\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
