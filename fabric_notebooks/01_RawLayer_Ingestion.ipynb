{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a78830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import notebookutils\n",
    "\n",
    "# Add utils directory to path\n",
    "sys.path.append('/lakehouse/default/Files/notebooks/utils')\n",
    "\n",
    "from g4s_api_client import G4SApiClient\n",
    "from keyvault_client import get_api_key_from_keyvault\n",
    "from delta_manager import DeltaTableManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Parameters\n",
    "KEY_VAULT_URL = \"https://your-keyvault.vault.azure.net/\"  # Update with your Key Vault URL\n",
    "SQL_ENDPOINT = \"your-sql-endpoint\"  # SQL endpoint for metadata tables\n",
    "DATABASE_NAME = \"your-database\"  # Database containing AcademySecurity table\n",
    "\n",
    "# Runtime parameters (can be passed from pipeline)\n",
    "sync_scope = \"FULL\"  # Options: FULL, STUDENTS, TEACHING, ASSESSMENT, ATTAINMENT, ATTENDANCE, TIMETABLE, BEHAVIOUR, USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb8f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Delta Table Manager\n",
    "delta_mgr = DeltaTableManager(spark)\n",
    "\n",
    "# API Endpoint Configuration\n",
    "ENDPOINTS = {\n",
    "    \"STUDENTS\": [\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/students\", \"name\": \"student_details\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/students/education-details\", \"name\": \"education_details\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/students/general-attributes\", \"name\": \"general_attributes\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/students/demographic-attributes\", \"name\": \"demographic_attributes\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/students/send-attributes\", \"name\": \"send_attributes\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/students/sensitive-attributes\", \"name\": \"sensitive_attributes\"}\n",
    "    ],\n",
    "    \"TEACHING\": [\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/teaching/departments\", \"name\": \"departments\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/teaching/subjects\", \"name\": \"subjects\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/teaching/groups\", \"name\": \"groups\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/teaching/group-students\", \"name\": \"group_students\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/teaching/teachers\", \"name\": \"teachers\"}\n",
    "    ],\n",
    "    \"ASSESSMENT\": [\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/assessment/markbooks\", \"name\": \"markbooks\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/assessment/marksheet-grades\", \"name\": \"marksheet_grades\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/assessment/markslot-marks\", \"name\": \"markslot_marks\"}\n",
    "    ],\n",
    "    \"ATTAINMENT\": [\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/attainment/prior-attainment\", \"name\": \"prior_attainment\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/attainment/grade-names\", \"name\": \"grade_names\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/attainment/grades\", \"name\": \"grades\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/attainment/exam-results\", \"name\": \"exam_results\"}\n",
    "    ],\n",
    "    \"ATTENDANCE\": [\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/attendance/codes\", \"name\": \"attendance_codes\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/attendance/student-lesson-marks\", \"name\": \"student_lesson_marks\", \"requires_date\": True},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/attendance/student-session-marks/date/{date}\", \"name\": \"student_session_marks\", \"requires_date\": True},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/attendance/student-session-summaries\", \"name\": \"student_session_summaries\"}\n",
    "    ],\n",
    "    \"TIMETABLE\": [\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/timetable/calendar\", \"name\": \"calendar\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/timetable/periods\", \"name\": \"periods\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/timetable/classes\", \"name\": \"timetable_classes\"}\n",
    "    ],\n",
    "    \"BEHAVIOUR\": [\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/behaviour/classifications\", \"name\": \"behaviour_classifications\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/behaviour/event-types\", \"name\": \"behaviour_event_types\"},\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/behaviour/events\", \"name\": \"behaviour_events\"}\n",
    "    ],\n",
    "    \"USERS\": [\n",
    "        {\"endpoint\": \"/customer/v1/academic-years/{academicYear}/users/staff\", \"name\": \"staff\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5031f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch academy configurations from metadata table\n",
    "def get_active_academies():\n",
    "    \"\"\"Retrieve active academy configurations from SQL metadata table\"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        AcademyCode,\n",
    "        Name,\n",
    "        CurrentAcademicYear,\n",
    "        KeyVaultSecretName,\n",
    "        LowestYear,\n",
    "        HighestYear,\n",
    "        GetLessonAttendance,\n",
    "        GetSessionAttendance,\n",
    "        AttendanceFrom,\n",
    "        AttendanceTo,\n",
    "        GetBehaviour,\n",
    "        BehaviourFrom,\n",
    "        BehaviourTo\n",
    "    FROM sec.AcademySecurity\n",
    "    WHERE Active = 1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read from SQL endpoint using Spark\n",
    "    df = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", f\"jdbc:sqlserver://{SQL_ENDPOINT}\") \\\n",
    "        .option(\"dbtable\", f\"({query}) AS academy_config\") \\\n",
    "        .option(\"database\", DATABASE_NAME) \\\n",
    "        .option(\"authentication\", \"ActiveDirectoryIntegrated\") \\\n",
    "        .load()\n",
    "    \n",
    "    return df.collect()\n",
    "\n",
    "# For Fabric, you might use the SQL Analytics endpoint directly:\n",
    "# academies = spark.sql(\"SELECT * FROM sec.AcademySecurity WHERE Active = 1\").collect()\n",
    "\n",
    "print(\"Fetching active academies...\")\n",
    "academies = get_active_academies()\n",
    "print(f\"Found {len(academies)} active academies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee28412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log sync results\n",
    "def log_sync_result(academy_code, dataset, endpoint, success, record_count=None, exception=None, inner_exception=None):\n",
    "    \"\"\"Log sync result to tracking table\"\"\"\n",
    "    from pyspark.sql import Row\n",
    "    \n",
    "    result_row = Row(\n",
    "        AcademyCode=academy_code,\n",
    "        DataSet=dataset,\n",
    "        EndPoint=endpoint,\n",
    "        LoggedAt=datetime.utcnow(),\n",
    "        Result=success,\n",
    "        RecordCount=record_count,\n",
    "        Exception=exception,\n",
    "        InnerException=inner_exception\n",
    "    )\n",
    "    \n",
    "    result_df = spark.createDataFrame([result_row])\n",
    "    \n",
    "    # Write to SyncResults table\n",
    "    result_df.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", f\"jdbc:sqlserver://{SQL_ENDPOINT}\") \\\n",
    "        .option(\"dbtable\", \"sec.SyncResults\") \\\n",
    "        .option(\"database\", DATABASE_NAME) \\\n",
    "        .option(\"authentication\", \"ActiveDirectoryIntegrated\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aba8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main ingestion function\n",
    "def ingest_endpoint_data(academy, endpoint_config, api_client):\n",
    "    \"\"\"Fetch data from a single endpoint and store in raw Delta table\"\"\"\n",
    "    academy_code = academy.AcademyCode\n",
    "    academic_year = academy.CurrentAcademicYear\n",
    "    endpoint = endpoint_config[\"endpoint\"]\n",
    "    endpoint_name = endpoint_config[\"name\"]\n",
    "    \n",
    "    try:\n",
    "        print(f\"Fetching {endpoint_name} for {academy_code} ({academic_year})...\")\n",
    "        \n",
    "        # Handle date-based endpoints\n",
    "        if endpoint_config.get(\"requires_date\"):\n",
    "            # For attendance endpoints, fetch data for the configured date range\n",
    "            date_from = academy.AttendanceFrom if hasattr(academy, 'AttendanceFrom') else None\n",
    "            date_to = academy.AttendanceTo if hasattr(academy, 'AttendanceTo') else None\n",
    "            \n",
    "            if date_from:\n",
    "                date_str = date_from.strftime(\"%Y-%m-%d\")\n",
    "                data = api_client.fetch_all_data(endpoint, academic_year, date=date_str)\n",
    "            else:\n",
    "                print(f\"Skipping {endpoint_name} - no date range configured\")\n",
    "                return\n",
    "        else:\n",
    "            data = api_client.fetch_all_data(endpoint, academic_year)\n",
    "        \n",
    "        if not data:\n",
    "            print(f\"No data returned for {endpoint_name}\")\n",
    "            log_sync_result(academy_code, academic_year, endpoint, True, 0)\n",
    "            return\n",
    "        \n",
    "        # Add metadata to each record\n",
    "        enriched_data = []\n",
    "        for record in data:\n",
    "            enriched_record = {\n",
    "                **record,\n",
    "                \"_academy_code\": academy_code,\n",
    "                \"_academic_year\": academic_year,\n",
    "                \"_endpoint\": endpoint_name,\n",
    "                \"_ingested_at\": datetime.utcnow().isoformat()\n",
    "            }\n",
    "            enriched_data.append(enriched_record)\n",
    "        \n",
    "        # Write to raw Delta table\n",
    "        raw_table_name = f\"raw_g4s_{endpoint_name}\"\n",
    "        \n",
    "        # Delete existing partition before writing\n",
    "        try:\n",
    "            if spark.catalog.tableExists(raw_table_name):\n",
    "                delta_mgr.delete_partition(\n",
    "                    raw_table_name,\n",
    "                    f\"_academy_code = '{academy_code}' AND _academic_year = '{academic_year}'\"\n",
    "                )\n",
    "        except:\n",
    "            pass  # Table might not exist yet\n",
    "        \n",
    "        # Write data\n",
    "        delta_mgr.write_raw_json(\n",
    "            enriched_data,\n",
    "            raw_table_name,\n",
    "            partition_cols=[\"_academy_code\", \"_academic_year\"],\n",
    "            mode=\"append\"\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Successfully ingested {len(data)} records for {endpoint_name}\")\n",
    "        log_sync_result(academy_code, academic_year, endpoint, True, len(data))\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"✗ Error ingesting {endpoint_name}: {error_msg}\")\n",
    "        log_sync_result(academy_code, academic_year, endpoint, False, exception=error_msg)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f83243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all academies and endpoints\n",
    "def process_sync(sync_scope=\"FULL\"):\n",
    "    \"\"\"Main processing loop for API sync\"\"\"\n",
    "    \n",
    "    # Determine which endpoint groups to process\n",
    "    if sync_scope == \"FULL\":\n",
    "        endpoint_groups = ENDPOINTS.keys()\n",
    "    else:\n",
    "        endpoint_groups = [sync_scope] if sync_scope in ENDPOINTS else []\n",
    "    \n",
    "    if not endpoint_groups:\n",
    "        print(f\"Invalid sync scope: {sync_scope}\")\n",
    "        return\n",
    "    \n",
    "    total_start = datetime.now()\n",
    "    \n",
    "    for academy in academies:\n",
    "        academy_code = academy.AcademyCode\n",
    "        secret_name = academy.KeyVaultSecretName\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing Academy: {academy_code} - {academy.Name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # Retrieve API key from Key Vault\n",
    "            api_key = get_api_key_from_keyvault(KEY_VAULT_URL, secret_name)\n",
    "            api_client = G4SApiClient(api_key)\n",
    "            \n",
    "            # Process each endpoint group\n",
    "            for group_name in endpoint_groups:\n",
    "                print(f\"\\n--- Processing {group_name} endpoints ---\")\n",
    "                \n",
    "                for endpoint_config in ENDPOINTS[group_name]:\n",
    "                    ingest_endpoint_data(academy, endpoint_config, api_client)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing academy {academy_code}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    total_end = datetime.now()\n",
    "    duration = (total_end - total_start).total_seconds()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Sync completed in {duration:.2f} seconds\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Execute the sync\n",
    "process_sync(sync_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa317e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize raw tables after ingestion\n",
    "print(\"\\nOptimizing raw Delta tables...\")\n",
    "\n",
    "for group_name, endpoints in ENDPOINTS.items():\n",
    "    for endpoint_config in endpoints:\n",
    "        table_name = f\"raw_g4s_{endpoint_config['name']}\"\n",
    "        try:\n",
    "            if spark.catalog.tableExists(table_name):\n",
    "                delta_mgr.optimize_table(table_name, z_order_cols=[\"_academy_code\", \"_academic_year\"])\n",
    "                print(f\"✓ Optimized {table_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to optimize {table_name}: {str(e)}\")\n",
    "\n",
    "print(\"\\nRaw layer ingestion complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
