{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4787f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Parameters\n",
    "sync_scope = \"FULL\"  # FULL, STUDENTS, TEACHING, ASSESSMENT, ATTAINMENT, ATTENDANCE, TIMETABLE, BEHAVIOUR, USERS\n",
    "skip_raw = False\n",
    "skip_base = False\n",
    "\n",
    "print(f\"=\" * 80)\n",
    "print(f\"G4S API Sync Orchestration\")\n",
    "print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Sync Scope: {sync_scope}\")\n",
    "print(f\"Skip Raw Layer: {skip_raw}\")\n",
    "print(f\"Skip Base Layer: {skip_base}\")\n",
    "print(f\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71b08ca",
   "metadata": {},
   "source": [
    "## Step 1: Raw Layer Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3488e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_raw:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 1: Raw Layer Ingestion\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    raw_start = time.time()\n",
    "    \n",
    "    # Run raw layer ingestion notebook\n",
    "    # In Fabric, use mssparkutils.notebook.run()\n",
    "    try:\n",
    "        result = mssparkutils.notebook.run(\n",
    "            \"01_RawLayer_Ingestion\",\n",
    "            timeoutSeconds=3600,  # 1 hour timeout\n",
    "            args={\"sync_scope\": sync_scope}\n",
    "        )\n",
    "        \n",
    "        raw_duration = time.time() - raw_start\n",
    "        print(f\"\\n✓ Raw layer ingestion completed in {raw_duration:.2f} seconds\")\n",
    "        print(f\"Result: {result}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Raw layer ingestion failed: {str(e)}\")\n",
    "        raise\n",
    "else:\n",
    "    print(\"\\nSkipping raw layer ingestion (skip_raw=True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952bd473",
   "metadata": {},
   "source": [
    "## Step 2: Base Layer Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b7a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_base:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 2: Base Layer Transformation\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    base_start = time.time()\n",
    "    \n",
    "    # Define notebooks to run based on sync scope\n",
    "    transformation_notebooks = []\n",
    "    \n",
    "    if sync_scope == \"FULL\":\n",
    "        transformation_notebooks = [\n",
    "            \"02_BaseLayer_Students\",\n",
    "            \"03_BaseLayer_Teaching_Assessment\",\n",
    "            # Add more transformation notebooks as needed\n",
    "        ]\n",
    "    elif sync_scope == \"STUDENTS\":\n",
    "        transformation_notebooks = [\"02_BaseLayer_Students\"]\n",
    "    elif sync_scope in [\"TEACHING\", \"ASSESSMENT\"]:\n",
    "        transformation_notebooks = [\"03_BaseLayer_Teaching_Assessment\"]\n",
    "    # Add more conditions for other domains\n",
    "    \n",
    "    # Run each transformation notebook\n",
    "    for notebook in transformation_notebooks:\n",
    "        print(f\"\\nRunning {notebook}...\")\n",
    "        try:\n",
    "            result = mssparkutils.notebook.run(\n",
    "                notebook,\n",
    "                timeoutSeconds=1800,  # 30 minutes timeout\n",
    "                args={}\n",
    "            )\n",
    "            print(f\"✓ {notebook} completed successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ {notebook} failed: {str(e)}\")\n",
    "            # Continue with other notebooks even if one fails\n",
    "            continue\n",
    "    \n",
    "    base_duration = time.time() - base_start\n",
    "    print(f\"\\n✓ Base layer transformation completed in {base_duration:.2f} seconds\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nSkipping base layer transformation (skip_base=True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51414a",
   "metadata": {},
   "source": [
    "## Step 3: Data Quality and Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5625ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: Data Quality and Summary Report\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Query sync results from tracking table\n",
    "recent_sync_results = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        AcademyCode,\n",
    "        EndPoint,\n",
    "        DataSet,\n",
    "        Result,\n",
    "        RecordCount,\n",
    "        LoggedAt,\n",
    "        Exception\n",
    "    FROM sec.SyncResults\n",
    "    WHERE LoggedAt >= DATEADD(hour, -1, GETUTCDATE())\n",
    "    ORDER BY LoggedAt DESC\n",
    "\"\"\")\n",
    "\n",
    "# Show results\n",
    "display(recent_sync_results)\n",
    "\n",
    "# Count successes and failures\n",
    "success_count = recent_sync_results.filter(col(\"Result\") == True).count()\n",
    "failure_count = recent_sync_results.filter(col(\"Result\") == False).count()\n",
    "\n",
    "print(f\"\\nSync Results Summary:\")\n",
    "print(f\"  Successful syncs: {success_count}\")\n",
    "print(f\"  Failed syncs: {failure_count}\")\n",
    "\n",
    "if failure_count > 0:\n",
    "    print(\"\\n⚠ Some syncs failed. Review the details above.\")\n",
    "    failed_syncs = recent_sync_results.filter(col(\"Result\") == False)\n",
    "    display(failed_syncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table row counts\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Table Record Counts\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def get_table_count(table_name):\n",
    "    try:\n",
    "        if spark.catalog.tableExists(table_name):\n",
    "            return spark.table(table_name).count()\n",
    "        else:\n",
    "            return \"N/A\"\n",
    "    except:\n",
    "        return \"Error\"\n",
    "\n",
    "# Base layer tables\n",
    "base_tables = [\n",
    "    \"base_students\",\n",
    "    \"base_education_details\",\n",
    "    \"base_student_attributes\",\n",
    "    \"base_departments\",\n",
    "    \"base_subjects\",\n",
    "    \"base_groups\",\n",
    "    \"base_group_students\",\n",
    "    \"base_teachers\",\n",
    "    \"base_markbooks\",\n",
    "    \"base_marksheet_grades\",\n",
    "    \"base_markslot_marks\"\n",
    "]\n",
    "\n",
    "print(\"\\nBase Layer Tables:\")\n",
    "for table in base_tables:\n",
    "    count = get_table_count(table)\n",
    "    print(f\"  {table:40} {count:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bb5c4a",
   "metadata": {},
   "source": [
    "## Step 4: Optimize Delta Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5779f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: Optimize Delta Tables\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Optimize base layer tables\n",
    "for table in base_tables:\n",
    "    try:\n",
    "        if spark.catalog.tableExists(table):\n",
    "            print(f\"Optimizing {table}...\")\n",
    "            spark.sql(f\"OPTIMIZE {table} ZORDER BY (Academy, DataSet)\")\n",
    "            print(f\"✓ Optimized {table}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to optimize {table}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065975f2",
   "metadata": {},
   "source": [
    "## Completion Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdec08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"G4S API SYNC COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Completed: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Scope: {sync_scope}\")\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(\"  1. Review sync results in sec.SyncResults table\")\n",
    "print(\"  2. Validate data quality in base layer tables\")\n",
    "print(\"  3. Create/refresh any downstream semantic models or reports\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
